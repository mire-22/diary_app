import datetime
from typing import Dict, Any, List
import os
import json
import streamlit as st
import sys
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from utils.prompt_manager import PromptManager

class PeriodAnalyzer:
    """æœŸé–“åˆ†ææ©Ÿèƒ½ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, ai_analyzer=None):
        self.ai_analyzer = ai_analyzer
        self.use_gemini = False
        self.model = None
        self.prompt_manager = PromptManager()
        
        # AIã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã‹ã‚‰Geminiè¨­å®šã‚’å–å¾—
        if ai_analyzer:
            self.use_gemini = ai_analyzer.use_gemini
            self.model = ai_analyzer.model
    
    def analyze_period_summary(self, period_data: List[Dict[str, Any]], start_date: str, end_date: str, mode: str = "default", custom_prompt: str = "") -> Dict[str, Any]:
        """æŒ‡å®šæœŸé–“ã®æ—¥è¨˜ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹é€ åŒ–ã—ã¦ã¾ã¨ã‚ã‚‹"""
        if not period_data:
            return self._create_empty_summary(start_date, end_date, mode)
        
        # æœŸé–“ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«ã¾ã¨ã‚ã‚‹
        combined_text = self._combine_period_data(period_data)
        
        # LLMã§æ§‹é€ åŒ–åˆ†æ
        prompt = self._create_period_analysis_prompt(combined_text, start_date, end_date, mode, custom_prompt)
        
        if self.use_gemini and self.model:
            return self._analyze_period_with_gemini(prompt, start_date, end_date, mode)
        else:
            return self._mock_period_analysis(period_data, start_date, end_date, mode)
    
    def _create_empty_summary(self, start_date: str, end_date: str, mode: str = "default") -> Dict[str, Any]:
        """ç©ºã®æœŸé–“ã¾ã¨ã‚ã‚’ä½œæˆ"""
        return {
            "period": f"{start_date} ã€œ {end_date}",
            "mode": mode,
            "summary": "ã“ã®æœŸé–“ã®æ—¥è¨˜ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚",
            "key_themes": [],
            "emotional_journey": [],
            "insights": [],
            "growth_areas": [],
            "recommendations": []
        }
    
    def _combine_period_data(self, period_data: List[Dict[str, Any]]) -> str:
        """æœŸé–“ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«ã¾ã¨ã‚ã‚‹"""
        combined_text = ""
        for entry in period_data:
            combined_text += f"\n=== {entry['date']} ===\n"
            combined_text += f"æ—¥è¨˜: {entry['text']}\n"
            
            # QAãƒã‚§ãƒ¼ãƒ³ã‚’è¿½åŠ 
            qa_chain = entry.get('qa_chain', [])
            if qa_chain:
                combined_text += "è³ªå•ã¨å›ç­”:\n"
                for i, qa in enumerate(qa_chain):
                    combined_text += f"Q{i+1}: {qa['question']}\n"
                    combined_text += f"A{i+1}: {qa['answer']}\n"
            
            # åˆ†æçµæœã‚‚è¿½åŠ 
            combined_text += f"ãƒˆãƒ”ãƒƒã‚¯: {', '.join(entry.get('topics', []))}\n"
            combined_text += f"æ„Ÿæƒ…: {', '.join(entry.get('emotions', []))}\n"
            combined_text += f"æ€è€ƒ: {', '.join(entry.get('thoughts', []))}\n"
            combined_text += f"ç›®æ¨™: {', '.join(entry.get('goals', []))}\n"
            combined_text += "\n"
        
        return combined_text
    
    def _create_period_analysis_prompt(self, combined_text: str, start_date: str, end_date: str, mode: str = "default", custom_prompt: str = "") -> str:
        """æœŸé–“åˆ†æç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ"""
        try:
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
            prompt = self.prompt_manager.get_period_analysis_prompt(
                mode=mode,
                start_date=start_date,
                end_date=end_date,
                combined_text=combined_text,
                custom_prompt=custom_prompt
            )
            return prompt
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¿”ã™
            print(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return f"""
# æœŸé–“åˆ†æ
æœŸé–“: {start_date} ã€œ {end_date}
ãƒ‡ãƒ¼ã‚¿: {combined_text[:500]}...
åˆ†æãƒ¢ãƒ¼ãƒ‰: {mode}

ã“ã®æœŸé–“ã®æ—¥è¨˜ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚
"""
    
    def _analyze_period_with_gemini(self, prompt: str, start_date: str, end_date: str, mode: str = "default") -> Dict[str, Any]:
        """Gemini APIã§æœŸé–“åˆ†æã‚’å®Ÿè¡Œ"""
        try:
            response = self.model.generate_content(prompt)
            import re
            
            if mode in ["default", "kpt", "ywt"]:
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ¼ãƒ‰ã€KPTãƒ¢ãƒ¼ãƒ‰ã€YWTãƒ¢ãƒ¼ãƒ‰: JSONå½¢å¼ã‚’æœŸå¾…
                match = re.search(r'\{[\s\S]*\}', response.text)
                if match:
                    result = json.loads(match.group(0))
                    # modeãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¿½åŠ 
                    result['mode'] = mode
                    return result
            else:
                # ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ¼ãƒ‰: ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§è¿”ã™
                return {
                    "period": f"{start_date} ã€œ {end_date}",
                    "mode": mode,
                    "custom_result": response.text,
                    "raw_response": response.text
                }
                
        except Exception as e:
            print('Period analysis error:', e)
        
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
        return self._mock_period_analysis([], start_date, end_date, mode)
    
    def _mock_period_analysis(self, period_data: List[Dict[str, Any]], start_date: str, end_date: str, mode: str = "default") -> Dict[str, Any]:
        """ãƒ¢ãƒƒã‚¯æœŸé–“åˆ†æãƒ‡ãƒ¼ã‚¿"""
        if mode == "kpt":
            return {
                "period": f"{start_date} ã€œ {end_date}",
                "mode": "kpt",
                "summary": f"ã“ã®æœŸé–“ã®KPTåˆ†æã‚’è¡Œã„ã¾ã—ãŸã€‚{len(period_data)}ä»¶ã®ã‚¨ãƒ³ãƒˆãƒªã‚’åŸºã«åˆ†æã—ã¾ã—ãŸã€‚",
                "kpt_analysis": {
                    "keep": [
                        {
                            "topic": "ç¿’æ…£ãƒ»ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³",
                            "items": ["ç¶™ç¶šã™ã¹ãç¿’æ…£1", "ç¶™ç¶šã™ã¹ãç¿’æ…£2"],
                            "reason": "åŠ¹æœçš„ãªç¿’æ…£ã¨ã—ã¦å®šç€ã—ã¦ã„ã‚‹"
                        }
                    ],
                    "problem": [
                        {
                            "topic": "æ™‚é–“ç®¡ç†",
                            "items": ["æ”¹å–„ã™ã¹ãå•é¡Œ1", "æ”¹å–„ã™ã¹ãå•é¡Œ2"],
                            "impact": "åŠ¹ç‡æ€§ã«å½±éŸ¿ã—ã¦ã„ã‚‹"
                        }
                    ],
                    "try": [
                        {
                            "topic": "æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ",
                            "items": ["è©¦ã—ã¦ã¿ãŸã„ã“ã¨1", "è©¦ã—ã¦ã¿ãŸã„ã“ã¨2"],
                            "expected_effect": "æ”¹å–„ãŒæœŸå¾…ã•ã‚Œã‚‹"
                        }
                    ]
                },
                "key_themes": ["è‡ªå·±æˆé•·", "äººé–“é–¢ä¿‚", "ç›®æ¨™è¨­å®š"],
                "recommendations": [
                    "æ¯æ—¥ã®æŒ¯ã‚Šè¿”ã‚Šç¿’æ…£ã‚’ç¶™ç¶šã™ã‚‹",
                    "æ„Ÿæƒ…ã®å¤‰åŒ–ã‚’ã‚ˆã‚Šè©³ç´°ã«è¨˜éŒ²ã™ã‚‹",
                    "é€±æ¬¡ã§ã®ç›®æ¨™è¦‹ç›´ã—ã‚’è¡Œã†"
                ]
            }
        elif mode == "ywt":
            return {
                "period": f"{start_date} ã€œ {end_date}",
                "mode": "ywt",
                "summary": f"ã“ã®æœŸé–“ã®YWTåˆ†æã‚’è¡Œã„ã¾ã—ãŸã€‚{len(period_data)}ä»¶ã®ã‚¨ãƒ³ãƒˆãƒªã‚’åŸºã«åˆ†æã—ã¾ã—ãŸã€‚",
                "ywt_analysis": {
                    "yatta": [
                        {
                            "topic": "å­¦ç¿’ãƒ»ã‚¹ã‚­ãƒ«å‘ä¸Š",
                            "items": ["å®Ÿéš›ã«ã‚„ã£ãŸã“ã¨1", "å®Ÿéš›ã«ã‚„ã£ãŸã“ã¨2"],
                            "context": "å­¦ç¿’æ´»å‹•ã®èƒŒæ™¯ã‚„çŠ¶æ³"
                        }
                    ],
                    "wakatta": [
                        {
                            "topic": "è‡ªå·±ç†è§£",
                            "items": ["ã‚ã‹ã£ãŸã“ã¨1", "ã‚ã‹ã£ãŸã“ã¨2"],
                            "insight": "è‡ªå·±ç™ºè¦‹ã‚„å­¦ã³ã®è©³ç´°"
                        }
                    ],
                    "tsugi": [
                        {
                            "topic": "æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—",
                            "items": ["æ¬¡ã«ã‚„ã‚‹ã“ã¨1", "æ¬¡ã«ã‚„ã‚‹ã“ã¨2"],
                            "reason": "æ¬¡ã«ã‚„ã‚‹ç†ç”±ã‚„æœŸå¾…åŠ¹æœ"
                        }
                    ]
                },
                "key_themes": ["è‡ªå·±æˆé•·", "å­¦ç¿’", "ç›®æ¨™è¨­å®š"],
                "recommendations": [
                    "å­¦ã‚“ã ã“ã¨ã‚’å®Ÿè·µã«æ´»ã‹ã™",
                    "ç¶™ç¶šçš„ãªå­¦ç¿’ç¿’æ…£ã‚’ç¶­æŒã™ã‚‹",
                    "å®šæœŸçš„ãªæŒ¯ã‚Šè¿”ã‚Šã‚’è¡Œã†"
                ]
            }
        else:  # default mode
            return {
                "period": f"{start_date} ã€œ {end_date}",
                "mode": "default",
                "summary": f"ã“ã®æœŸé–“ã¯{len(period_data)}ä»¶ã®æ—¥è¨˜ãŒã‚ã‚Šã€æ§˜ã€…ãªå‡ºæ¥äº‹ã‚„æ„Ÿæƒ…ã®å¤‰åŒ–ãŒè¨˜éŒ²ã•ã‚Œã¾ã—ãŸã€‚",
                "key_themes": ["è‡ªå·±æˆé•·", "äººé–“é–¢ä¿‚", "ç›®æ¨™è¨­å®š"],
                "emotional_journey": [
                    {"date": start_date, "emotion": "æœŸå¾…", "context": "æ–°ã—ã„æœŸé–“ã®é–‹å§‹"},
                    {"date": end_date, "emotion": "é”æˆæ„Ÿ", "context": "æœŸé–“ã®æŒ¯ã‚Šè¿”ã‚Š"}
                ],
                "insights": [
                    "ç¶™ç¶šçš„ãªè¨˜éŒ²ã®é‡è¦æ€§",
                    "æ„Ÿæƒ…ã®å¤‰åŒ–ã‚’è¦³å¯Ÿã™ã‚‹ã“ã¨ã®ä¾¡å€¤",
                    "ç›®æ¨™è¨­å®šã¨æŒ¯ã‚Šè¿”ã‚Šã®åŠ¹æœ"
                ],
                "growth_areas": [
                    "æ„Ÿæƒ…ã®è‡ªå·±èªè­˜",
                    "ç›®æ¨™ã®å…·ä½“åŒ–"
                ],
                "recommendations": [
                    "æ¯æ—¥ã®æŒ¯ã‚Šè¿”ã‚Šç¿’æ…£ã‚’ç¶™ç¶šã™ã‚‹",
                    "æ„Ÿæƒ…ã®å¤‰åŒ–ã‚’ã‚ˆã‚Šè©³ç´°ã«è¨˜éŒ²ã™ã‚‹",
                    "é€±æ¬¡ã§ã®ç›®æ¨™è¦‹ç›´ã—ã‚’è¡Œã†"
                ]
            }
    
    def analyze_weekly_trends(self, period_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """é€±æ¬¡ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æï¼ˆæ‹¡å¼µæ©Ÿèƒ½ï¼‰"""
        if not period_data:
            return {"weekly_trends": [], "summary": "ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚"}
        
        # é€±æ¬¡ã§ãƒ‡ãƒ¼ã‚¿ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        weekly_groups = {}
        for entry in period_data:
            date = datetime.datetime.strptime(entry['date'], '%Y-%m-%d')
            week_start = date - datetime.timedelta(days=date.weekday())
            week_key = week_start.strftime('%Y-%m-%d')
            
            if week_key not in weekly_groups:
                weekly_groups[week_key] = []
            weekly_groups[week_key].append(entry)
        
        # é€±æ¬¡åˆ†æ
        weekly_trends = []
        for week_start, entries in weekly_groups.items():
            week_end = (datetime.datetime.strptime(week_start, '%Y-%m-%d') + 
                       datetime.timedelta(days=6)).strftime('%Y-%m-%d')
            
            # æ„Ÿæƒ…ã®é›†è¨ˆ
            emotions = []
            for entry in entries:
                emotions.extend(entry.get('emotions', []))
            
            # ãƒˆãƒ”ãƒƒã‚¯ã®é›†è¨ˆ
            topics = []
            for entry in entries:
                topics.extend(entry.get('topics', []))
            
            weekly_trends.append({
                "week": f"{week_start} ã€œ {week_end}",
                "entry_count": len(entries),
                "top_emotions": self._get_top_items(emotions, 3),
                "top_topics": self._get_top_items(topics, 3),
                "entries": entries
            })
        
        return {
            "weekly_trends": weekly_trends,
            "summary": f"{len(weekly_trends)}é€±é–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã¾ã—ãŸã€‚"
        }
    
    def analyze_monthly_summary(self, period_data: List[Dict[str, Any]], year_month: str) -> Dict[str, Any]:
        """æœˆæ¬¡ã‚µãƒãƒªãƒ¼åˆ†æï¼ˆæ‹¡å¼µæ©Ÿèƒ½ï¼‰"""
        if not period_data:
            return {"monthly_summary": {}, "summary": "ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚"}
        
        # æŒ‡å®šæœˆã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿
        monthly_data = [
            entry for entry in period_data 
            if entry['date'].startswith(year_month)
        ]
        
        if not monthly_data:
            return {"monthly_summary": {}, "summary": f"{year_month}ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"}
        
        # æœˆæ¬¡çµ±è¨ˆ
        total_entries = len(monthly_data)
        total_words = sum(len(entry['text']) for entry in monthly_data)
        
        # æ„Ÿæƒ…ãƒ»ãƒˆãƒ”ãƒƒã‚¯ã®é›†è¨ˆ
        all_emotions = []
        all_topics = []
        all_thoughts = []
        all_goals = []
        
        for entry in monthly_data:
            all_emotions.extend(entry.get('emotions', []))
            all_topics.extend(entry.get('topics', []))
            all_thoughts.extend(entry.get('thoughts', []))
            all_goals.extend(entry.get('goals', []))
        
        return {
            "monthly_summary": {
                "period": year_month,
                "total_entries": total_entries,
                "total_words": total_words,
                "avg_words_per_entry": total_words // total_entries if total_entries > 0 else 0,
                "top_emotions": self._get_top_items(all_emotions, 5),
                "top_topics": self._get_top_items(all_topics, 5),
                "top_thoughts": self._get_top_items(all_thoughts, 3),
                "top_goals": self._get_top_items(all_goals, 3),
                "entries": monthly_data
            },
            "summary": f"{year_month}ã®æœˆæ¬¡ã‚µãƒãƒªãƒ¼ã‚’ä½œæˆã—ã¾ã—ãŸã€‚"
        }
    
    def _get_top_items(self, items: List[str], top_n: int) -> List[tuple]:
        """ã‚¢ã‚¤ãƒ†ãƒ ã®å‡ºç¾å›æ•°ã‚’é›†è¨ˆã—ã¦ä¸Šä½Nå€‹ã‚’è¿”ã™"""
        item_counts = {}
        for item in items:
            item_counts[item] = item_counts.get(item, 0) + 1
        
        return sorted(item_counts.items(), key=lambda x: x[1], reverse=True)[:top_n]
    
    def create_export_text(self, summary_result: Dict[str, Any], period_data: List[Dict[str, Any]]) -> str:
        """ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆç”¨ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ"""
        mode = summary_result.get('mode', 'default')
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
        print(f"create_export_text called with mode: {mode}")
        print(f"summary_result keys: {list(summary_result.keys())}")
        print(f"period_data length: {len(period_data)}")
        
        export_text = f"""
# æ—¥è¨˜æœŸé–“ã¾ã¨ã‚
{summary_result.get('period', '')}
åˆ†æãƒ¢ãƒ¼ãƒ‰: {mode}

"""
        
        if mode == 'custom':
            # ã‚«ã‚¹ã‚¿ãƒ åˆ†æçµæœ
            export_text += f"## ğŸ¨ ã‚«ã‚¹ã‚¿ãƒ åˆ†æçµæœ\n"
            custom_result = summary_result.get('custom_result', '')
            if custom_result:
                export_text += f"{custom_result}\n"
            else:
                export_text += "ã‚«ã‚¹ã‚¿ãƒ åˆ†æã®çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚\n"
        elif mode == 'kpt':
            # KPTåˆ†æçµæœ
            export_text += f"## ğŸ¯ KPTåˆ†æçµæœ\n"
            export_text += f"### æ¦‚è¦\n"
            export_text += f"{summary_result.get('summary', '')}\n"
            
            kpt_analysis = summary_result.get('kpt_analysis', {})
            if kpt_analysis:
                export_text += f"\n### âœ… Keepï¼ˆç¶™ç¶šã™ã¹ãã“ã¨ï¼‰\n"
                for i, keep in enumerate(kpt_analysis.get('keep', []), 1):
                    export_text += f"{i}. ãƒˆãƒ”ãƒƒã‚¯: {keep.get('topic', '')}\n"
                    export_text += f"   é …ç›®: {', '.join(keep.get('items', []))}\n"
                    export_text += f"   ç†ç”±: {keep.get('reason', '')}\n\n"
                
                export_text += f"### âš ï¸ Problemï¼ˆæ”¹å–„ã™ã¹ãå•é¡Œï¼‰\n"
                for i, problem in enumerate(kpt_analysis.get('problem', []), 1):
                    export_text += f"{i}. ãƒˆãƒ”ãƒƒã‚¯: {problem.get('topic', '')}\n"
                    export_text += f"   é …ç›®: {', '.join(problem.get('items', []))}\n"
                    export_text += f"   å½±éŸ¿: {problem.get('impact', '')}\n\n"
                
                export_text += f"### ğŸš€ Tryï¼ˆè©¦ã—ã¦ã¿ãŸã„ã“ã¨ï¼‰\n"
                for i, try_item in enumerate(kpt_analysis.get('try', []), 1):
                    export_text += f"{i}. ãƒˆãƒ”ãƒƒã‚¯: {try_item.get('topic', '')}\n"
                    export_text += f"   é …ç›®: {', '.join(try_item.get('items', []))}\n"
                    export_text += f"   æœŸå¾…åŠ¹æœ: {try_item.get('expected_effect', '')}\n\n"
            
            export_text += f"\n### ä¸»è¦ãƒ†ãƒ¼ãƒ\n"
            for i, theme in enumerate(summary_result.get('key_themes', []), 1):
                export_text += f"{i}. {theme}\n"
            
            export_text += f"\n### æ¨å¥¨äº‹é …\n"
            for i, rec in enumerate(summary_result.get('recommendations', []), 1):
                export_text += f"{i}. {rec}\n"
        elif mode == 'ywt':
            # YWTåˆ†æçµæœ
            export_text += f"## ğŸ“ YWTåˆ†æçµæœ\n"
            export_text += f"### æ¦‚è¦\n"
            export_text += f"{summary_result.get('summary', '')}\n"
            
            ywt_analysis = summary_result.get('ywt_analysis', {})
            if ywt_analysis:
                export_text += f"\n### âœ… Yattaï¼ˆã‚„ã£ãŸã“ã¨ï¼‰\n"
                for i, yatta in enumerate(ywt_analysis.get('yatta', []), 1):
                    export_text += f"{i}. ãƒˆãƒ”ãƒƒã‚¯: {yatta.get('topic', '')}\n"
                    export_text += f"   é …ç›®: {', '.join(yatta.get('items', []))}\n"
                    export_text += f"   èƒŒæ™¯: {yatta.get('context', '')}\n\n"
                
                export_text += f"### ğŸ’¡ Wakattaï¼ˆã‚ã‹ã£ãŸã“ã¨ï¼‰\n"
                for i, wakatta in enumerate(ywt_analysis.get('wakatta', []), 1):
                    export_text += f"{i}. ãƒˆãƒ”ãƒƒã‚¯: {wakatta.get('topic', '')}\n"
                    export_text += f"   é …ç›®: {', '.join(wakatta.get('items', []))}\n"
                    export_text += f"   ç™ºè¦‹: {wakatta.get('insight', '')}\n\n"
                
                export_text += f"### ğŸš€ Tsugiï¼ˆæ¬¡ã‚„ã‚‹ã“ã¨ï¼‰\n"
                for i, tsugi in enumerate(ywt_analysis.get('tsugi', []), 1):
                    export_text += f"{i}. ãƒˆãƒ”ãƒƒã‚¯: {tsugi.get('topic', '')}\n"
                    export_text += f"   é …ç›®: {', '.join(tsugi.get('items', []))}\n"
                    export_text += f"   ç†ç”±: {tsugi.get('reason', '')}\n\n"
            
            export_text += f"\n### ä¸»è¦ãƒ†ãƒ¼ãƒ\n"
            for i, theme in enumerate(summary_result.get('key_themes', []), 1):
                export_text += f"{i}. {theme}\n"
            
            export_text += f"\n### æ¨å¥¨äº‹é …\n"
            for i, rec in enumerate(summary_result.get('recommendations', []), 1):
                export_text += f"{i}. {rec}\n"
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåˆ†æçµæœ
            export_text += f"## ğŸ“Š ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåˆ†æçµæœ\n"
            export_text += f"### æ¦‚è¦\n"
            export_text += f"{summary_result.get('summary', '')}\n"
            
            export_text += f"\n### ä¸»è¦ãƒ†ãƒ¼ãƒ\n"
            for i, theme in enumerate(summary_result.get('key_themes', []), 1):
                export_text += f"{i}. {theme}\n"
            
            export_text += f"\n### æ„Ÿæƒ…ã®è»Œè·¡\n"
            for journey in summary_result.get('emotional_journey', []):
                export_text += f"- {journey.get('date', '')}: {journey.get('emotion', '')} - {journey.get('context', '')}\n"
            
            export_text += f"\n### æ´å¯Ÿ\n"
            for i, insight in enumerate(summary_result.get('insights', []), 1):
                export_text += f"{i}. {insight}\n"
            
            export_text += f"\n### æˆé•·é ˜åŸŸ\n"
            for i, area in enumerate(summary_result.get('growth_areas', []), 1):
                export_text += f"{i}. {area}\n"
            
            export_text += f"\n### æ¨å¥¨äº‹é …\n"
            for i, rec in enumerate(summary_result.get('recommendations', []), 1):
                export_text += f"{i}. {rec}\n"
        
        # å…ƒãƒ‡ãƒ¼ã‚¿
        export_text += f"\n## ğŸ“Š å…ƒãƒ‡ãƒ¼ã‚¿ ({len(period_data)}ä»¶)\n"
        if period_data:
            for entry in period_data:
                export_text += f"\n### {entry.get('date', 'Unknown Date')}\n"
                export_text += f"å†…å®¹: {entry.get('text', 'No content')}\n"
                export_text += f"ãƒˆãƒ”ãƒƒã‚¯: {', '.join(entry.get('topics', []))}\n"
                export_text += f"æ„Ÿæƒ…: {', '.join(entry.get('emotions', []))}\n"
                
                qa_chain = entry.get('qa_chain', [])
                if qa_chain:
                    export_text += "è³ªå•ã¨å›ç­”:\n"
                    for i, qa in enumerate(qa_chain):
                        export_text += f"Q{i+1}: {qa.get('question', '')}\n"
                        export_text += f"A{i+1}: {qa.get('answer', '')}\n"
        else:
            export_text += "å…ƒãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\n"
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
        print(f"Export text length: {len(export_text)} characters")
        
        return export_text 